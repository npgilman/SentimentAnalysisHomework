{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754e7235",
   "metadata": {},
   "source": [
    "<h1>Step 1: Exploratory Data Analysis.</h1></br> This stage is the very initial stage of your\n",
    "data analysis. You may want to know the size and sentiment distribution of\n",
    "the dataset. You may also want to examine if there are any missing values.\n",
    "This initial data analysis stage helps you to have a better understanding of the\n",
    "dataset before you build your sentiment classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "253577ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fee2ab85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  Sentiment                                               Text\n",
       "0      0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1      1          0  is upset that he can't update his Facebook by ...\n",
       "2      2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3      3          0    my whole body feels itchy and like its on fire \n",
       "4      4          0  @nationwideclass no, it's not behaving at all....\n",
       "5      5          0                      @Kwesidei not the whole crew \n",
       "6      6          0                                        Need a hug \n",
       "7      7          0  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8      8          0               @Tatiana_K nope they didn't have it \n",
       "9      9          0                          @twittera que me muera ? "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)\n",
    "#train_data.isnull().sum()\n",
    "#train_data['Sentiment'].value_counts()\n",
    "#train_data['Sentiment'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b8252",
   "metadata": {},
   "source": [
    "<h1>Step 2: Text Preprocessing.</h1></br> You need to prepare your training and testing\n",
    "dataset. Specifically for this problem, you need to preprocess the discussion\n",
    "texts, you may want to convert all words into lowercase and remove digital\n",
    "numbers and special characters. Please refer to our slides and class\n",
    "discussions for a full list of text preprocessing steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10d52640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra whitespace and convert upper to lower\n",
    "train_data = train_data.convert_dtypes()\n",
    "train_data['Text'] = train_data['Text'].str.strip()\n",
    "train_data['Text'] = train_data['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6b0c3f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "import re\n",
    "# regex removes urls, user mentions and special characters respectively\n",
    "regex_pattern = re.compile('(http)[\\S]* ?|(@)[\\S]* ?|[^A-Z^a-z ]', flags=re.IGNORECASE)\n",
    "train_data['Text'] = train_data['Text'].str.replace(regex_pattern, '', regex=True)\n",
    "train_data['Text'] = train_data['Text'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d4d7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\twinb\\.conda\\envs\\cis4930\\lib\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remove stop words and stemming\n",
    "# (based on research, stemming seems like a better choice for sentiment analysis rather than lemmatization)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# removing and stemming in one pass takes 5 minutes\n",
    "train_data = train_data.reset_index()\n",
    "for index, row in train_data.iterrows():\n",
    "    test_arr = [word for word in train_data['Text'].iloc[index] if not word in english_stopwords]\n",
    "    test_arr = [stemmer.stem(word) for word in test_arr]\n",
    "    train_data.at[index, 'Text'] = test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef95df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Index</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[awww, that, bummer, shoulda, got, david, carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[upset, cant, updat, facebook, text, might, cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[dive, mani, time, ball, manag, save, rest, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[behav, im, mad, cant, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[whole, crew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[need, hug]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, long, time, see, ye, rain, bit, bit, lol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[nope, didnt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>[que, muera]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Index  Sentiment                                               Text\n",
       "0      0      0          0  [awww, that, bummer, shoulda, got, david, carr...\n",
       "1      1      1          0  [upset, cant, updat, facebook, text, might, cr...\n",
       "2      2      2          0  [dive, mani, time, ball, manag, save, rest, go...\n",
       "3      3      3          0             [whole, bodi, feel, itchi, like, fire]\n",
       "4      4      4          0                        [behav, im, mad, cant, see]\n",
       "5      5      5          0                                      [whole, crew]\n",
       "6      6      6          0                                        [need, hug]\n",
       "7      7      7          0  [hey, long, time, see, ye, rain, bit, bit, lol...\n",
       "8      8      8          0                                      [nope, didnt]\n",
       "9      9      9          0                                       [que, muera]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca360c2",
   "metadata": {},
   "source": [
    "<h1>Step 3: Linguistic Feature Extraction.</h1></br> You will extract linguistic features\n",
    "from the processed texts. You may consider a wide range of features we\n",
    "covered in the class, including bag-of-words, tf*idf, word2vec, etc. You may\n",
    "also consider other word-embedding semantic features such as Glove or\n",
    "BERT, but these are not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f60370cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262679"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bow\n",
    "#gather unique words\n",
    "import itertools\n",
    "corpus = set(itertools.chain.from_iterable(train_data.Text))\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefaa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe = train_data.copy(deep=True)\n",
    "# def createBagOfWords(l_doc):\n",
    "#   tf_diz = dict.fromkeys(corpus,0)\n",
    "#   for word in l_doc:\n",
    "#       tf_diz[word]=l_doc.count(word)\n",
    "#   return tf_diz\n",
    "# bow1 = calculateBOW(wordset,l_doc1)\n",
    "# bow2 = calculateBOW(wordset,l_doc2)\n",
    "# bow3 = calculateBOW(wordset,l_doc3)\n",
    "# df_bow = pd.DataFrame([bow1,bow2,bow3])\n",
    "# df_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf*idf\n",
    "# word2vec\n",
    "from datetime import datetime\n",
    "BOW_df = pd.DataFrame()\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "then = datetime.now()\n",
    "\n",
    "print(then - now)\n",
    "BOW_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cc45d",
   "metadata": {},
   "source": [
    "<h1>Step 4: Build your sentiment classification model.</h1></br> Provide the extracted\n",
    "set of linguistic features from the training dataset to your classification model.\n",
    "Note that this is a binary classification problem. You may want to start with\n",
    "classical machine learning algorithms such as Logistic Regression, SVM, Naive\n",
    "Bayes, and Random Forest. You may also consider neural-network-based\n",
    "classifiers, such as multilayer perceptron, but these are not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6eb9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045cea7",
   "metadata": {},
   "source": [
    "<h1>Step 5: Model evaluation.</h1></br> Evaluate your model performance with the\n",
    "provided testing dataset. Recall the evaluation metrics we covered in the class\n",
    "and select appropriate metrics for this problem. Please compare the\n",
    "performance of different classifiers using the same linguistic feature and the\n",
    "performance of the same classifier using different linguistic features. Finally,\n",
    "discuss your experimental results and submit the assignment report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddcab727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work in progress."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
